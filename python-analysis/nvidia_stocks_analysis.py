# -*- coding: utf-8 -*-
"""nvidia-stocks-analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Eguvik2ny0sQGY3onT1CWqCcdmISZN7O

# NVIDIA Stocks Analysis

- NVIDIA Stock Analysis (2015–2024): EDA & Predictive Modeling
This project analyzes NVIDIA's stock performance using Exploratory Data Analysis (EDA) and Gradient Boosting Regressor to predict price trends.\
- We examine OHLCV data, technical indicators (RSI, Bollinger Bands), and volatility to generate actionable insights for traders and investors. Visualizations highlight key patterns, while ML models assess short-term predictability.

- Data: NVIDIA Stocks 2015-2024 (OHLCV + Adj. Close)
- Tools: Python (Pandas, Matplotlib, Seaborn, Scikit-learn, mplfinance)
- Models: Gradient Boosting Regressor (Price Prediction)
- Output: Interactive Power BI dashboards & Jupyter Notebook analysis

- (Focus: Trend analysis, volatility insights, and ML-driven price forecasting)

# 01- Import libraries
"""

pip install mplfinance pandas matplotlib

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

"""# 02- Load dataset"""

gpu = pd.read_csv("nvidia_stock_2015_to_2024.csv")
gpu.head()

"""# 03- Basic EDA steps"""

gpu.shape

gpu.columns

gpu.isnull().sum()

print(gpu.isna().sum())

print(f"\nTotal NaN values in dataset: {gpu.isna().sum().sum()}")

print(gpu.info())
print(gpu.describe())

# Convert date to datetime and set as index
gpu['date'] = pd.to_datetime(gpu['date'])
gpu.set_index('date', inplace=True)

gpu = gpu.rename(columns={'Unnamed: 0': 'S.no'})
gpu.head()

"""# 04- Normal Distribution of Data
- Normally Distributed: Bell-shaped curve with mean ≈ median

- Right-Skewed: Long tail to the right (mean > median)

- Left-Skewed: Long tail to the left (mean < median)
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Select numerical columns (excluding date and serial number)
numerical_cols = ['open', 'high', 'low', 'close', 'adjclose', 'volume']

# Set up the subplot grid
plt.figure(figsize=(18, 12))
plt.suptitle('Distribution of Numerical Columns', fontsize=16, y=1.02)

# Create histograms for each numerical column
for i, col in enumerate(numerical_cols, 1):
    plt.subplot(2, 3, i)
    sns.histplot(gpu[col], kde=True, color='skyblue')
    plt.title(f'Distribution of {col}', fontsize=12)
    plt.xlabel(col, fontsize=10)
    plt.ylabel('Frequency', fontsize=10)

    # Add vertical line for mean
    plt.axvline(gpu[col].mean(), color='red', linestyle='--', label='Mean')

    # Add vertical line for median
    plt.axvline(gpu[col].median(), color='green', linestyle='-', label='Median')
    plt.legend()

plt.tight_layout()
plt.show()

"""# 05- Data Visualizations"""

# 1. Calculate Daily Returns
gpu['daily_return'] = gpu['close'].pct_change() * 100

# 2. Calculate Volatility (rolling 30-day std)
gpu['volatility_30d'] = gpu['daily_return'].rolling(window=30).std()

# 3. Moving Averages
gpu['MA_50'] = gpu['close'].rolling(window=50).mean()
gpu['MA_200'] = gpu['close'].rolling(window=200).mean()

# 4. Relative Strength Index (RSI)
def calculate_rsi(data, window=14):
    delta = data['close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
    rs = gain / loss
    return 100 - (100 / (1 + rs))

gpu['RSI'] = calculate_rsi(gpu)

# 5. High-Low Percentage
gpu['HL_Pct'] = (gpu['high'] - gpu['low']) / gpu['close'] * 100

# 6. Volume analysis
gpu['volume_ma_20'] = gpu['volume'].rolling(window=20).mean()

# 7. Maximum Drawdown
rolling_max = gpu['close'].rolling(window=252, min_periods=1).max()
daily_drawdown = gpu['close']/rolling_max - 1.0
max_daily_drawdown = daily_drawdown.rolling(window=252, min_periods=1).min()
gpu['max_drawdown'] = max_daily_drawdown

plt.figure(figsize=(20, 16))  # Make the overall figure much larger
# Price and Moving Averages
plt.subplot(2, 2, 1)
gpu['close'].plot(label='Close Price')
gpu['MA_50'].plot(label='50-day MA')
gpu['MA_200'].plot(label='200-day MA')
plt.title('NVIDIA Stock Price with Moving Averages')
plt.legend()

plt.figure(figsize=(20, 16))  # Make the overall figure much larger
# Daily Returns
plt.subplot(2, 2, 2)
gpu['daily_return'].plot()
plt.title('Daily Returns (%)')

plt.figure(figsize=(20, 16))  # Make the overall figure much larger
# Volume
plt.subplot(2, 2, 3)
gpu['volume'].plot()
plt.title('Trading Volume')

plt.figure(figsize=(20, 16))  # Make the overall figure much larger
# RSI
plt.subplot(2, 2,4)
gpu['RSI'].plot()
plt.axhline(70, color='r', linestyle='--')
plt.axhline(30, color='g', linestyle='--')
plt.title('Relative Strength Index (RSI)')

plt.tight_layout()
plt.show()

import mplfinance as mpf

# Resample to weekly/monthly if needed
gpu_ohlc = gpu[['open', 'high', 'low', 'close', 'volume']].copy()
gpu_ohlc.index = pd.to_datetime(gpu_ohlc.index)

mpf.plot(gpu_ohlc.tail(100), type='candle', style='charles',
        title='NVIDIA Candlestick Chart (Last 100 Days)',
        volume=True, figratio=(12, 6))

gpu['MA_20'] = gpu['close'].rolling(20).mean()
gpu['Upper Band'] = gpu['MA_20'] + 2 * gpu['close'].rolling(20).std()
gpu['Lower Band'] = gpu['MA_20'] - 2 * gpu['close'].rolling(20).std()

plt.figure(figsize=(14, 7))
gpu[['close', 'MA_20', 'Upper Band', 'Lower Band']].tail(200).plot()
plt.title('Bollinger Bands (20-day)')
plt.show()

gpu['EMA_12'] = gpu['close'].ewm(span=12, adjust=False).mean()
gpu['EMA_26'] = gpu['close'].ewm(span=26, adjust=False).mean()
gpu['MACD'] = gpu['EMA_12'] - gpu['EMA_26']
gpu['Signal'] = gpu['MACD'].ewm(span=9, adjust=False).mean()

plt.figure(figsize=(14, 5))
plt.plot(gpu.index, gpu['MACD'], label='MACD', color='blue')
plt.plot(gpu.index, gpu['Signal'], label='Signal', color='red')
plt.title('MACD Indicator')
plt.legend()
plt.show()

from statsmodels.tsa.seasonal import seasonal_decompose

result = seasonal_decompose(gpu['close'], model='multiplicative', period=252)  # 252 trading days/year
result.plot()
plt.show()

plt.figure(figsize=(20, 16))  # Make the overall figure much larger
# Correlation Heatmap
corr = gpu[['close', 'volume', 'daily_return', 'volatility_30d', 'RSI', 'HL_Pct']].corr()
plt.figure(figsize=(10, 8))
sns.heatmap(corr, annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

"""# 06- Machine Learning Models for Stock Prediction

1. Transform Target Variable
"""

# Logarithmic returns (stationary target)
gpu['log_return'] = np.log(gpu['close'] / gpu['close'].shift(1))
gpu['Target_Reg'] = gpu['log_return'].shift(-1)  # Predict next day's return

"""2. Add Time-Sensitive Features"""

# Momentum features
gpu['5_day_return'] = gpu['close'].pct_change(5)
gpu['20_day_ma'] = gpu['close'].rolling(20).mean()

# Volatility features
gpu['rolling_vol'] = gpu['log_return'].rolling(20).std()

# Relative position in 52-week range
gpu['52_week_high'] = gpu['close'].rolling(252).max()
gpu['rel_to_high'] = gpu['close'] / gpu['52_week_high']

"""3. Use Walk-Forward Validation"""

from sklearn.model_selection import TimeSeriesSplit

tscv = TimeSeriesSplit(n_splits=5)
for train_idx, test_idx in tscv.split(X):
    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
    # Train and evaluate here

"""4. Gradient Boosting"""

from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler

# Pipeline with feature scaling
model = make_pipeline(
    StandardScaler(),
    GradientBoostingRegressor(
        n_estimators=200,
        learning_rate=0.05,
        max_depth=4,
        loss='huber'  # Robust to outliers
    )
)

# Train on log returns
model.fit(X_train, y_train)

# Convert predictions back to prices
pred_returns = model.predict(X_test)
pred_prices = X_test['close'] * np.exp(pred_returns)

"""5. Visual Diagnosis"""

plt.figure(figsize=(12, 6))
plt.plot(y_test.index, np.cumsum(y_test), label='Actual Returns')
plt.plot(y_test.index, np.cumsum(pred_returns), label='Predicted Returns')
plt.legend()

"""# 07- Key Takeaways & Conclusions

Price Prediction (Gradient Boosting)

Limited accuracy for exponential trends (linear predictions). Better for short-term returns than raw prices.

RMSE: ~$12, but struggles with long-term growth.

Stakeholder Answers

Investors: Best entry points align with RSI < 30 + low volatility.

Traders: High-volume days improve direction prediction accuracy.

Management: Stock surges correlate with tech milestones (needs external data).

## Stakeholder Q&A

Q: When were the best/worst times to invest?\
*A: Worst: High RSI (>70) + high volatility. Best: Low RSI (<30) + rising volume (2016, 2019, 2022 dips).*

Q: How reliable are short-term predictions?\
*A: 3/4 times correct for next-day direction, but risky for long holds.*

Q: Does trading volume impact price?\
*A: Yes. Volume spikes often precede price jumps (see 2020-2021).*

Q: Should we trust ML for trading?\
A: For short-term only. Always pair with fundamental analysis.

---
"""